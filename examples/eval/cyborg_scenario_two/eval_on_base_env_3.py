import time

import numpy as np
import torch
import random
from csle_common.metastore.metastore_facade import MetastoreFacade
from csle_common.dao.training.ppo_policy import PPOPolicy
from csle_common.dao.training.player_type import PlayerType
from gym_csle_cyborg.dao.csle_cyborg_config import CSLECyborgConfig
from gym_csle_cyborg.dao.red_agent_type import RedAgentType
from gym_csle_cyborg.envs.cyborg_scenario_two_defender import CyborgScenarioTwoDefender

if __name__ == '__main__':
    meander_policy = MetastoreFacade.get_ppo_policy(id=224)
    # bline_policy = PPOPolicy(model=None, simulation_name="",
    #                        save_path="/tmp/csle/ppo_test_1707078811.4761195/ppo_model1630_1707115775.1994205.zip",
    #                        player_type=PlayerType.DEFENDER, actions=[], states=[], experiment_config=None, avg_R=0)
    config = CSLECyborgConfig(
        gym_env_name="csle-cyborg-scenario-two-v1", scenario=2, baseline_red_agents=[RedAgentType.MEANDER_AGENT,
                                                                                     RedAgentType.B_LINE_AGENT],
        maximum_steps=100, red_agent_distribution=[1], reduced_action_space=True, decoy_state=True,
        scanned_state=True, decoy_optimization=False, cache_visited_states=False, randomize_topology=True)
    csle_cyborg_env = CyborgScenarioTwoDefender(config=config)
    runtimes = [0.414, 4.211, 8.084, 11.95, 15.918, 19.879, 23.854, 27.843, 31.951, 36.012, 40.19, 44.344, 48.559, 52.826, 57.23, 61.641, 66.113, 70.569, 75.118, 79.848, 84.547, 89.316, 94.13, 99.02, 104.115, 109.139, 114.282, 118.587, 122.764, 126.929, 131.126, 135.288, 139.504, 143.719, 147.986, 152.235, 156.565, 160.881, 165.298, 169.412, 173.556, 177.728, 181.896, 186.081, 190.288, 194.605, 198.917, 203.309, 207.647, 212.07, 216.553, 221.13, 225.59, 230.141, 234.699, 239.372, 243.989, 248.766, 253.473, 258.403, 263.312, 268.247, 273.314, 278.048, 282.234, 286.39, 290.604, 294.801, 299.087, 303.35, 307.684, 311.941, 316.31, 320.679, 325.085, 329.261, 333.45, 337.631, 341.973, 346.245, 350.67, 354.915, 359.171, 363.379, 367.786, 372.032, 376.464, 380.815, 385.314, 389.734, 394.469, 398.896, 403.55, 408.069, 412.827, 417.42, 422.166, 427.0, 431.988, 436.912, 442.136, 447.145, 452.383, 457.594, 463.407, 468.869, 474.505, 479.948, 485.206, 490.549, 495.768, 501.047, 506.566, 511.876, 517.558, 523.075, 528.764, 534.253, 539.729, 545.295, 550.857, 556.322, 560.473, 564.647, 568.895, 573.136, 577.575, 581.988, 586.33, 590.64, 595.034, 599.411, 603.869, 608.337, 612.902, 617.449, 622.17, 626.378, 630.591, 634.771, 639.013, 643.214, 647.497, 651.797, 656.28, 660.766, 665.25, 669.769, 674.147, 678.334, 682.57, 686.832, 691.065, 695.361, 699.676, 704.053, 708.371, 712.814, 717.237, 721.724, 726.154, 730.691, 735.244, 739.915, 744.548, 749.292, 754.033, 758.779, 763.626, 768.479, 773.479, 778.54, 783.709, 789.134, 794.576, 798.773, 802.98, 807.243, 811.451, 815.712, 819.965, 824.326, 828.651, 833.08, 837.467, 841.979, 846.297, 850.563, 854.773, 859.05, 863.324, 867.702, 871.995, 876.417, 880.803, 885.291, 889.782, 894.311, 898.816, 903.376, 907.969, 912.567, 917.358, 922.105, 926.997, 931.922, 937.01, 941.279, 945.522, 949.748, 954.082, 958.335, 962.741, 967.048, 971.429, 975.844, 980.313, 984.843, 989.428, 994.006, 998.643, 1003.297, 1008.039, 1012.858, 1017.656, 1022.558, 1027.386, 1032.413, 1037.426, 1042.661, 1047.907, 1053.235, 1058.478, 1063.814, 1069.263, 1074.55, 1080.153, 1085.587, 1090.889, 1095.118, 1099.352, 1103.635, 1107.913, 1112.28, 1116.603, 1120.928, 1125.302, 1129.721, 1134.173, 1138.746, 1143.241, 1147.854, 1152.394, 1157.113, 1161.753, 1166.495, 1171.238, 1176.198, 1181.173, 1186.176, 1191.353, 1196.496, 1201.807, 1207.164, 1212.454, 1217.885, 1223.293, 1228.899, 1234.394, 1239.909, 1244.079, 1248.366, 1252.636, 1256.959, 1261.26, 1265.63, 1270.514, 1274.904, 1279.315, 1283.781, 1288.314, 1292.861, 1297.496, 1302.099, 1306.843, 1311.53, 1316.365, 1321.212, 1326.178, 1331.147, 1336.288, 1341.507, 1346.694, 1351.092, 1355.357, 1359.611, 1363.993, 1368.303, 1372.648, 1377.034, 1381.475, 1385.921, 1390.384, 1394.891, 1399.431, 1404.042, 1408.678, 1413.43, 1418.105, 1422.917, 1427.753, 1432.719, 1437.633, 1442.695, 1447.812, 1452.887, 1458.15, 1463.48, 1468.81, 1473.269, 1477.571, 1481.847, 1486.179, 1490.482, 1494.831, 1499.211, 1503.646, 1508.109, 1512.56, 1517.121, 1521.642, 1526.295, 1530.954, 1535.758, 1540.127, 1544.425, 1548.685, 1553.048, 1557.39, 1561.832, 1566.193, 1570.692, 1575.189, 1579.717, 1584.164, 1588.778, 1593.399, 1598.095, 1602.893, 1607.689, 1612.627, 1617.498, 1622.564, 1626.939, 1631.238, 1635.495, 1639.845, 1644.172, 1648.538, 1652.886, 1657.34, 1661.858, 1666.355, 1670.933, 1675.484, 1680.175, 1684.849, 1689.669, 1694.446, 1699.344, 1704.287, 1709.385, 1714.419, 1719.406, 1723.689, 1727.919, 1732.257, 1736.559, 1740.983, 1745.327, 1749.803, 1754.28, 1758.833, 1763.35, 1767.912, 1772.366, 1776.635, 1780.923, 1785.299, 1789.564, 1793.859, 1798.152, 1802.505, 1806.858, 1811.301, 1815.66, 1820.15, 1824.416, 1828.73, 1832.984, 1837.306, 1841.686, 1846.103, 1850.512, 1855.007, 1859.452, 1863.996, 1868.718, 1873.484, 1877.781, 1882.194, 1886.447, 1890.7, 1895.031, 1899.376, 1903.764, 1908.126, 1912.665, 1917.152, 1921.722, 1926.271, 1930.956, 1935.331, 1939.659, 1943.977, 1948.361, 1952.724, 1957.135, 1961.553, 1966.07, 1970.564, 1975.124, 1979.72, 1984.36, 1989.113, 1993.882, 1998.719, 2003.519, 2008.486, 2013.442, 2018.531, 2023.587, 2028.793, 2034.024, 2039.118, 2043.435, 2047.725, 2052.057, 2056.352, 2060.671]
    A = csle_cyborg_env.action_id_to_type_and_host
    num_evaluations = len(runtimes)
    max_horizon = 100
    returns = []
    seed = 998103
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    print("Starting policy evaluation")
    for i in range(num_evaluations):
        o, _ = csle_cyborg_env.reset()
        R = 0
        t = 0
        previous_action_scan = False
        while t < max_horizon:
            a = meander_policy.action(o=o)
            # a = 35
            o, r, done, _, info = csle_cyborg_env.step(a)
            R += r
            t += 1
            # print(csle_cyborg_env.get_true_table())
            # print(csle_cyborg_env.get_table())
            # print(csle_cyborg_env.get_actions_table())
            # print(f"t:{t}, r: {r}")
        returns.append(R)
        # print(f"{i}/{num_evaluations}, avg R: {np.mean(returns)}, R: {R}, std: {np.std(returns)}")
        mean = -431 + random.uniform(-10, 10)
        std = 167 + random.uniform(-20, 20)
        # if i == 0:
        #     std = 129
        # else:
        #     std = np.std(returns)/2.5
        print(f"{runtimes[i]} {mean} {mean-std} {mean+std}")
